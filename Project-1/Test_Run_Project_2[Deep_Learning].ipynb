{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test Run Project-2[Deep Learning].ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0wgbl-pCxZt",
        "colab_type": "code",
        "outputId": "9dbbf599-eeff-480a-9a18-c7bd20db7015",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "print(\"PyTorch Version: \",torch.__version__)\n",
        "print(\"Torchvision Version: \",torchvision.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch Version:  1.1.0\n",
            "Torchvision Version:  0.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRHS-PwY97ZR",
        "colab_type": "code",
        "outputId": "a37fd81f-c346-439c-e8c9-048e1a3b7d68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qq81iXFtCxZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Top level data directory. Here we assume the format of the directory conforms\n",
        "# to the ImageFolder structure\n",
        "data_dir = \"drive/My Drive/data /dataset_updated\"\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 5\n",
        "\n",
        "model_name = 'resnet'\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 7\n",
        "\n",
        "# Number of epochs to train for\n",
        "num_epochs = 30\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VtOI-wiCxZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=30, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "        print()\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "    return(val_acc_history)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR2GxtQ3CxZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VWrXt7_CxZ_",
        "colab_type": "code",
        "outputId": "18140cb1-93d0-40b6-96d7-9cf94226c884",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"squeezenet\":\n",
        "        \"\"\" Squeezenet\n",
        "        \"\"\"\n",
        "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "        model_ft.num_classes = num_classes\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n",
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n",
            "100%|██████████| 46827520/46827520 [00:00<00:00, 135291472.78it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6qTTKfPCxaE",
        "colab_type": "code",
        "outputId": "4d377027-3b87-46cc-ed56-03cb3d7385c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(input_size),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "print(\"Initializing Datasets and Dataloaders...\")\n",
        "\n",
        "# Create training and validation datasets\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
        "# Create training and validation dataloaders\n",
        "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True) for x in ['train', 'val']}\n",
        "\n",
        "# Detect if we have a GPU available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing Datasets and Dataloaders...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdrICGqlCxaH",
        "colab_type": "code",
        "outputId": "d1609e28-ee2f-425a-ecc1-9d941f774c86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t fc.weight\n",
            "\t fc.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVqviVhSiT3M",
        "colab_type": "code",
        "outputId": "dd990b7d-840a-4884-a080-b60901d2b0cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "dataloaders_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': <torch.utils.data.dataloader.DataLoader at 0x7fcef24a1a58>,\n",
              " 'val': <torch.utils.data.dataloader.DataLoader at 0x7fcef24a1710>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhaGrK8CCxaK",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "6lRqbk9-CxaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAWY9X_1CxaP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AkD2Qx3ig-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAMHXCsViiTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaMlj70lCxaT",
        "colab_type": "text"
      },
      "source": [
        "### Training Pre-trained Network from Scratch\n",
        "\n",
        "We use ['resnet', 'alexnet', 'vgg', 'squeezenet', 'densenet'] and train them from scratch for a 7 class classification task. We finally plot the validation accuracies obtained from all the five pre-trained networks over 20 epochs. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OG5uWnbCxaU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_call(model_name, optimizer):\n",
        "    # Initialize the non-pretrained version of the model used for this run\n",
        "    model,_ = initialize_model(model_name, num_classes, feature_extract=True, use_pretrained=True)\n",
        "    model = model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    return(train_model(model, dataloaders_dict, criterion, optimizer))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O4UEHuSlgwa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## basically, we loop through each model in the model_list\n",
        "\n",
        "model_list = ['resnet', 'alexnet', 'vgg', 'squeezenet', 'densenet']\n",
        "\n",
        "acc_history_scratch = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLLyBjs4voVI",
        "colab_type": "code",
        "outputId": "a407a26f-f526-482b-d99f-1aeb0c804153",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2811
        }
      },
      "source": [
        "model_name = 'alexnet'\n",
        "acc_history_scratch[model_name] = train_call(model_name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/29\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:914: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6029312 bytes but only got 0. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1311848 bytes but only got 785. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:742: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 1.3738 Acc: 0.4222\n",
            "val Loss: 1.4045 Acc: 0.4871\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.1802 Acc: 0.5330\n",
            "val Loss: 0.9782 Acc: 0.6273\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.1158 Acc: 0.5646\n",
            "val Loss: 1.0082 Acc: 0.6402\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.0906 Acc: 0.5701\n",
            "val Loss: 0.8916 Acc: 0.6671\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.0606 Acc: 0.5929\n",
            "val Loss: 0.8929 Acc: 0.6554\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.0247 Acc: 0.6034\n",
            "val Loss: 0.8690 Acc: 0.6624\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.0523 Acc: 0.6033\n",
            "val Loss: 0.8445 Acc: 0.6671\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.0007 Acc: 0.6199\n",
            "val Loss: 0.8820 Acc: 0.6928\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 0.9853 Acc: 0.6315\n",
            "val Loss: 0.9888 Acc: 0.6367\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 0.9644 Acc: 0.6380\n",
            "val Loss: 0.8256 Acc: 0.6939\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 0.9939 Acc: 0.6326\n",
            "val Loss: 0.8356 Acc: 0.7196\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 0.9700 Acc: 0.6405\n",
            "val Loss: 0.8044 Acc: 0.6998\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.0321 Acc: 0.6188\n",
            "val Loss: 0.8743 Acc: 0.6589\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 0.9759 Acc: 0.6358\n",
            "val Loss: 0.8219 Acc: 0.7161\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 0.9585 Acc: 0.6458\n",
            "val Loss: 0.7812 Acc: 0.7009\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 0.9402 Acc: 0.6472\n",
            "val Loss: 0.7696 Acc: 0.7231\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 0.9611 Acc: 0.6499\n",
            "val Loss: 0.8618 Acc: 0.6811\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 0.9595 Acc: 0.6469\n",
            "val Loss: 0.7864 Acc: 0.7021\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 0.9654 Acc: 0.6478\n",
            "val Loss: 0.8160 Acc: 0.7325\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.0206 Acc: 0.6263\n",
            "val Loss: 0.7934 Acc: 0.7360\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 0.9793 Acc: 0.6455\n",
            "val Loss: 0.7739 Acc: 0.7290\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 0.9332 Acc: 0.6656\n",
            "val Loss: 0.7808 Acc: 0.6951\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 0.9349 Acc: 0.6609\n",
            "val Loss: 0.7563 Acc: 0.7243\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 0.9275 Acc: 0.6607\n",
            "val Loss: 0.8099 Acc: 0.7079\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 0.9468 Acc: 0.6568\n",
            "val Loss: 0.7530 Acc: 0.7243\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 0.9034 Acc: 0.6658\n",
            "val Loss: 0.8616 Acc: 0.7033\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 0.9745 Acc: 0.6421\n",
            "val Loss: 0.8393 Acc: 0.7138\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 0.9238 Acc: 0.6613\n",
            "val Loss: 0.8113 Acc: 0.7103\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 0.9372 Acc: 0.6595\n",
            "val Loss: 0.8537 Acc: 0.6659\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 0.9220 Acc: 0.6570\n",
            "val Loss: 0.7706 Acc: 0.7266\n",
            "\n",
            "Training complete in 41m 57s\n",
            "Best val Acc: 0.735981\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvvM0tsMwN6M",
        "colab_type": "code",
        "outputId": "4d53139a-165a-48b3-f5f8-cc9ae83dc5ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2811
        }
      },
      "source": [
        "model_name = 'squeezenet'\n",
        "acc_history_scratch[model_name] = train_call(model_name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/29\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:914: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6029312 bytes but only got 0. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1311848 bytes but only got 785. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:742: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 1.2750 Acc: 0.4881\n",
            "val Loss: 1.0438 Acc: 0.6121\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.1547 Acc: 0.5600\n",
            "val Loss: 1.0374 Acc: 0.6086\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.0920 Acc: 0.5883\n",
            "val Loss: 0.9981 Acc: 0.6390\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.0208 Acc: 0.6298\n",
            "val Loss: 0.9341 Acc: 0.6741\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 0.9811 Acc: 0.6521\n",
            "val Loss: 0.8834 Acc: 0.6904\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 0.9328 Acc: 0.6662\n",
            "val Loss: 0.8863 Acc: 0.6729\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 0.8980 Acc: 0.6810\n",
            "val Loss: 0.8120 Acc: 0.7173\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 0.8803 Acc: 0.6899\n",
            "val Loss: 0.7645 Acc: 0.7348\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 0.8557 Acc: 0.6965\n",
            "val Loss: 0.7752 Acc: 0.7290\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 0.8424 Acc: 0.6980\n",
            "val Loss: 0.8349 Acc: 0.6928\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 0.8425 Acc: 0.7013\n",
            "val Loss: 0.7770 Acc: 0.7348\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 0.8395 Acc: 0.6999\n",
            "val Loss: 0.7326 Acc: 0.7465\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 0.8160 Acc: 0.7088\n",
            "val Loss: 0.7651 Acc: 0.7418\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 0.8082 Acc: 0.7100\n",
            "val Loss: 0.7086 Acc: 0.7477\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 0.7965 Acc: 0.7195\n",
            "val Loss: 0.7516 Acc: 0.7383\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 0.7929 Acc: 0.7192\n",
            "val Loss: 0.7181 Acc: 0.7430\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 0.7938 Acc: 0.7151\n",
            "val Loss: 0.7434 Acc: 0.7313\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 0.7807 Acc: 0.7248\n",
            "val Loss: 0.6917 Acc: 0.7535\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 0.7739 Acc: 0.7209\n",
            "val Loss: 0.7437 Acc: 0.7430\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 0.7612 Acc: 0.7272\n",
            "val Loss: 0.7048 Acc: 0.7465\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 0.7568 Acc: 0.7256\n",
            "val Loss: 0.7866 Acc: 0.7150\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 0.7527 Acc: 0.7323\n",
            "val Loss: 0.7553 Acc: 0.7325\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 0.7613 Acc: 0.7279\n",
            "val Loss: 0.7537 Acc: 0.7266\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 0.7508 Acc: 0.7305\n",
            "val Loss: 0.7112 Acc: 0.7301\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 0.7514 Acc: 0.7302\n",
            "val Loss: 0.8749 Acc: 0.7150\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 0.7631 Acc: 0.7279\n",
            "val Loss: 0.7069 Acc: 0.7488\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 0.7464 Acc: 0.7307\n",
            "val Loss: 0.6943 Acc: 0.7477\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 0.7383 Acc: 0.7350\n",
            "val Loss: 0.7254 Acc: 0.7465\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 0.7591 Acc: 0.7332\n",
            "val Loss: 0.6722 Acc: 0.7629\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 0.7725 Acc: 0.7204\n",
            "val Loss: 0.7293 Acc: 0.7360\n",
            "\n",
            "Training complete in 39m 27s\n",
            "Best val Acc: 0.762850\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMVYZQC-h7Yb",
        "colab_type": "code",
        "outputId": "b56f81d1-3bd3-4693-87e9-37416228d8ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2811
        }
      },
      "source": [
        "model_name = 'densenet'\n",
        "acc_history_scratch[model_name] = train_call(model_name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/29\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:914: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6029312 bytes but only got 0. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1311848 bytes but only got 785. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:742: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 1.1357 Acc: 0.5587\n",
            "val Loss: 1.2022 Acc: 0.5829\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 0.9726 Acc: 0.6436\n",
            "val Loss: 1.2200 Acc: 0.6285\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 0.9061 Acc: 0.6687\n",
            "val Loss: 0.7325 Acc: 0.7418\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 0.8557 Acc: 0.6884\n",
            "val Loss: 0.7799 Acc: 0.7313\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 0.8111 Acc: 0.7070\n",
            "val Loss: 0.6730 Acc: 0.7792\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 0.7685 Acc: 0.7204\n",
            "val Loss: 0.7585 Acc: 0.7512\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 0.7454 Acc: 0.7236\n",
            "val Loss: 0.5783 Acc: 0.8178\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 0.7104 Acc: 0.7465\n",
            "val Loss: 0.7180 Acc: 0.7722\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 0.6719 Acc: 0.7561\n",
            "val Loss: 0.7304 Acc: 0.7465\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 0.6498 Acc: 0.7669\n",
            "val Loss: 0.6017 Acc: 0.8283\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 0.6244 Acc: 0.7755\n",
            "val Loss: 1.0956 Acc: 0.7862\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 0.6089 Acc: 0.7831\n",
            "val Loss: 0.5040 Acc: 0.8306\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 0.5860 Acc: 0.7903\n",
            "val Loss: 0.6365 Acc: 0.8166\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 0.5667 Acc: 0.7934\n",
            "val Loss: 0.6234 Acc: 0.8271\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 0.5449 Acc: 0.7998\n",
            "val Loss: 1.6014 Acc: 0.7967\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 0.5453 Acc: 0.7989\n",
            "val Loss: 0.5021 Acc: 0.8306\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 0.5238 Acc: 0.8114\n",
            "val Loss: 0.7054 Acc: 0.8271\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 0.5158 Acc: 0.8154\n",
            "val Loss: 0.4081 Acc: 0.8610\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 0.4998 Acc: 0.8162\n",
            "val Loss: 0.4834 Acc: 0.8364\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 0.4916 Acc: 0.8166\n",
            "val Loss: 0.4630 Acc: 0.8563\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 0.4629 Acc: 0.8328\n",
            "val Loss: 0.4769 Acc: 0.8446\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 0.4599 Acc: 0.8297\n",
            "val Loss: 0.4654 Acc: 0.8481\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 0.4378 Acc: 0.8372\n",
            "val Loss: 0.3930 Acc: 0.8598\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 0.4497 Acc: 0.8299\n",
            "val Loss: 0.5788 Acc: 0.8516\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 0.4227 Acc: 0.8435\n",
            "val Loss: 0.4503 Acc: 0.8621\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 0.4269 Acc: 0.8407\n",
            "val Loss: 0.4564 Acc: 0.8680\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 0.4085 Acc: 0.8463\n",
            "val Loss: 0.3644 Acc: 0.8703\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 0.4093 Acc: 0.8450\n",
            "val Loss: 0.3990 Acc: 0.8586\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 0.3997 Acc: 0.8521\n",
            "val Loss: 0.3438 Acc: 0.8762\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 0.3957 Acc: 0.8518\n",
            "val Loss: 0.3597 Acc: 0.8668\n",
            "\n",
            "Training complete in 87m 56s\n",
            "Best val Acc: 0.876168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRk8mC6fi5e6",
        "colab_type": "code",
        "outputId": "6355fbd6-8f98-4495-847c-c40e8d988f67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2811
        }
      },
      "source": [
        "model_name = 'vgg'\n",
        "acc_history_scratch[model_name] = train_call(model_name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/29\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6029312 bytes but only got 0. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1311848 bytes but only got 785. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:742: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:914: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 1.2640 Acc: 0.5593\n",
            "val Loss: 0.7090 Acc: 0.7675\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 0.9603 Acc: 0.6592\n",
            "val Loss: 0.8336 Acc: 0.7535\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 0.8754 Acc: 0.6969\n",
            "val Loss: 0.6666 Acc: 0.7710\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 0.8208 Acc: 0.7125\n",
            "val Loss: 0.7444 Acc: 0.7745\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 0.7570 Acc: 0.7328\n",
            "val Loss: 0.5722 Acc: 0.7932\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 0.7344 Acc: 0.7415\n",
            "val Loss: 0.7930 Acc: 0.7558\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 0.6991 Acc: 0.7531\n",
            "val Loss: 0.6180 Acc: 0.7769\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 0.6803 Acc: 0.7569\n",
            "val Loss: 0.5439 Acc: 0.8143\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 0.6590 Acc: 0.7657\n",
            "val Loss: 0.5606 Acc: 0.8049\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 0.6484 Acc: 0.7713\n",
            "val Loss: 0.5252 Acc: 0.8271\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 0.6241 Acc: 0.7779\n",
            "val Loss: 0.6957 Acc: 0.7558\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 0.6183 Acc: 0.7794\n",
            "val Loss: 0.4900 Acc: 0.8294\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 0.5883 Acc: 0.7901\n",
            "val Loss: 0.5458 Acc: 0.7956\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 0.5748 Acc: 0.7901\n",
            "val Loss: 0.5388 Acc: 0.8224\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 0.5761 Acc: 0.7990\n",
            "val Loss: 0.5170 Acc: 0.8201\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 0.5641 Acc: 0.7960\n",
            "val Loss: 0.4114 Acc: 0.8493\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 0.5501 Acc: 0.8035\n",
            "val Loss: 0.4646 Acc: 0.8341\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 0.5365 Acc: 0.8075\n",
            "val Loss: 0.4112 Acc: 0.8481\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 0.5221 Acc: 0.8144\n",
            "val Loss: 0.4123 Acc: 0.8516\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 0.5233 Acc: 0.8106\n",
            "val Loss: 0.4087 Acc: 0.8563\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 0.5162 Acc: 0.8170\n",
            "val Loss: 0.4321 Acc: 0.8505\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 0.5130 Acc: 0.8174\n",
            "val Loss: 0.4091 Acc: 0.8516\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 0.4947 Acc: 0.8259\n",
            "val Loss: 0.3827 Acc: 0.8586\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 0.4919 Acc: 0.8254\n",
            "val Loss: 0.3955 Acc: 0.8493\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 0.4873 Acc: 0.8294\n",
            "val Loss: 0.3931 Acc: 0.8563\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 0.4805 Acc: 0.8306\n",
            "val Loss: 0.4015 Acc: 0.8540\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 0.4749 Acc: 0.8301\n",
            "val Loss: 0.3974 Acc: 0.8633\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 0.4645 Acc: 0.8302\n",
            "val Loss: 0.3490 Acc: 0.8657\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 0.4579 Acc: 0.8403\n",
            "val Loss: 0.3712 Acc: 0.8540\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 0.4346 Acc: 0.8429\n",
            "val Loss: 0.3533 Acc: 0.8551\n",
            "\n",
            "Training complete in 92m 47s\n",
            "Best val Acc: 0.865654\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WMkRAFieFlb",
        "colab_type": "code",
        "outputId": "cb016e2d-131f-4154-cf88-efd0fa1ca2e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Plot the training curves of validation accuracy vs. number\n",
        "# of training epochs for the transfer learning method and\n",
        "# the model trained from scratch\n",
        "resnet = []\n",
        "alexnet = []\n",
        "vgg = []\n",
        "squeezenet = []\n",
        "densenet = []\n",
        "\n",
        "resnet = [h.cpu().numpy() for h in acc_history_scratch['resnet']]\n",
        "alexnet = [h.cpu().numpy() for h in acc_history_scratch['alexnet']]\n",
        "vgg = [h.cpu().numpy() for h in acc_history_scratch['vgg']]\n",
        "squeezenet = [h.cpu().numpy() for h in acc_history_scratch['squeezenet']]\n",
        "densenet = [h.cpu().numpy() for h in acc_history_scratch['densenet']]\n",
        "\n",
        "plt.title(\"Validation Accuracy vs. Epochs[Scratch]\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Validation Accuracy\")\n",
        "plt.plot(range(1,num_epochs+1),resnet,label=\"Resnet\")\n",
        "plt.plot(range(1,num_epochs+1),alexnet,label=\"Alexnet\")\n",
        "plt.plot(range(1,num_epochs+1),vgg,label=\"VGG\")\n",
        "plt.plot(range(1,num_epochs+1),squeezenet,label=\"Squeezenet\")\n",
        "plt.plot(range(1,num_epochs+1),densenet,label=\"Densenet\")\n",
        "# plt.plot(range(1,num_epochs+1),inception,label=\"Inception\")\n",
        "plt.ylim((0.4,0.9))\n",
        "plt.xticks(np.arange(1, num_epochs + 1, 2.0))\n",
        "plt.legend()\n",
        "plt.savefig(\"scratch_training_zoomed.jpg\", bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYMjEGAWDwWAwZPJ/wHxmdR7D3kcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-eQK3zDi_oU",
        "colab_type": "code",
        "outputId": "67b55449-62eb-4866-8ad2-8599e5e09c27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1577
        }
      },
      "source": [
        "acc_history_scratch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alexnet': [tensor(0.4871, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6273, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6402, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6671, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6554, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6624, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6671, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6928, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6367, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6939, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7196, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6998, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6589, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7161, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7009, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7231, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6811, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7021, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7325, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7360, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7290, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6951, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7243, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7079, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7243, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7033, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7138, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7103, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6659, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7266, device='cuda:0', dtype=torch.float64)],\n",
              " 'resnet': [tensor(0.7044, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.6881, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7138, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7874, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7839, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7687, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7850, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.8189, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.8119, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.8189, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.8096, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.8318, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.7886, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.8248, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.8259, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.8376, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.8563, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.8364, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.8376, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.8551, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.8259, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.8645, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.8715, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.8586, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.8680, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.8657, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.8738, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.8750, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.8470, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.8843, device='cuda:0', dtype=torch.float64)],\n",
              " 'vgg': [tensor(0.4206, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.2699, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.2699, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.2664, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.2699, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.2699, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.2699, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.2699, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.2699, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.2699, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.2699, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.2699, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.2699, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.2699, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.2699, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.2664, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.2699, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.2699, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.2664, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.2699, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.2664, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.2664, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.2699, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.2664, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.2664, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.2699, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.2699, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.2699, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.2664, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.2699, device='cuda:0', dtype=torch.float64)]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuvlXZNajAEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joggo1UVeOd-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shYZGgBjRgF4",
        "colab_type": "text"
      },
      "source": [
        "### Trying different Optimizers on Densenet\n",
        "\n",
        "*  SGD\n",
        "* Adam\n",
        "* Adagrad\n",
        "* RMSprop\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcpFThZljBKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer_history_feature = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVfmlJKJjBn1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE647u3EeR6M",
        "colab_type": "code",
        "outputId": "46ef24ef-8a6f-4640-841e-f9a9000b4bea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        }
      },
      "source": [
        "\n",
        "model_name = 'densenet'\n",
        "model,_ = initialize_model(model_name, num_classes, feature_extract=True, use_pretrained=True)\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
        "# Invoke traincall function with the optimizer\n",
        "optimizer_history_feature[optimizer] = train_model(model, dataloaders_dict, criterion, optimizer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/29\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:914: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6029312 bytes but only got 0. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1311848 bytes but only got 785. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:742: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.9794 Acc: 0.6705\n",
            "val Loss: 0.5242 Acc: 0.8411\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-357ae8420db9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Invoke traincall function with the optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0moptimizer_history_feature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-bd1d5a56df10>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, criterion, optimizer, num_epochs, is_inception)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# Iterate over data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \"\"\"\n\u001b[1;32m    131\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tfx8Ia-GjMot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model_name = 'densenet'\n",
        "model,_ = initialize_model(model_name, num_classes, feature_extract=True, use_pretrained=True)\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "# Invoke traincall function with the optimizer\n",
        "optimizer_history_feature[optimizer] = train_model(model, dataloaders_dict, criterion, optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5ff5v2ljTzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = 'densenet'\n",
        "model,_ = initialize_model(model_name, num_classes, feature_extract=True, use_pretrained=True)\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adagrad(model.parameters(), lr=0.0001)\n",
        "# Invoke traincall function with the optimizer\n",
        "optimizer_history_feature[optimizer] = train_model(model, dataloaders_dict, criterion, optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikF6Ay8zjZWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = 'densenet'\n",
        "model,_ = initialize_model(model_name, num_classes, feature_extract=True, use_pretrained=True)\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.RMSprop(model.parameters(), lr=0.0001)\n",
        "# Invoke traincall function with the optimizer\n",
        "optimizer_history_feature[optimizer] = train_model(model, dataloaders_dict, criterion, optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-LYw6TmjCkz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the training curves of validation accuracy vs. number\n",
        "# of training epochs for the transfer learning method\n",
        "sgd = []\n",
        "adam = []\n",
        "adagrad = []\n",
        "rmsprop = []\n",
        "\n",
        "sgd = [h.cpu().numpy() for h in optimizer_history['resnet']]\n",
        "adam = [h.cpu().numpy() for h in optimizer_history['alexnet']]\n",
        "adagrad = [h.cpu().numpy() for h in optimizer_history['vgg']]\n",
        "rmsprop = [h.cpu().numpy() for h in optimizer_history['squeezenet']]\n",
        "\n",
        "plt.title(\"Validation Accuracy vs. Epochs[Scratch]\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Validation Accuracy\")\n",
        "plt.plot(range(1,num_epochs+1),sgd,label=\"SGD\")\n",
        "plt.plot(range(1,num_epochs+1),adam,label=\"Adam\")\n",
        "plt.plot(range(1,num_epochs+1),adagrad,label=\"Adagrad\")\n",
        "plt.plot(range(1,num_epochs+1),rmsprop,label=\"RMSprop\")\n",
        "\n",
        "plt.ylim((0.4,0.9))\n",
        "plt.xticks(np.arange(1, num_epochs + 1, 2.0))\n",
        "plt.legend()\n",
        "plt.savefig(\"optimizer_training_zoomed.jpg\", bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pD2RC1KVkh69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer_history_scratch = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Olf0TRMIjC-2",
        "colab_type": "code",
        "outputId": "cc47e13b-68aa-42d6-ab30-1e6ee97b2b93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2757
        }
      },
      "source": [
        "model_name = 'densenet'\n",
        "model,_ = initialize_model(model_name, num_classes, feature_extract=False, use_pretrained=False)\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
        "# Invoke traincall function with the optimizer\n",
        "optimizer_history_scratch[optimizer] = train_model(model, dataloaders_dict, criterion, optimizer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/29\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6029312 bytes but only got 0. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1311848 bytes but only got 785. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:742: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:914: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 1.1690 Acc: 0.5630\n",
            "val Loss: 0.8674 Acc: 0.6939\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 0.9800 Acc: 0.6419\n",
            "val Loss: 0.7429 Acc: 0.7360\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 0.9091 Acc: 0.6679\n",
            "val Loss: 0.6961 Acc: 0.7512\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 0.8842 Acc: 0.6782\n",
            "val Loss: 0.6757 Acc: 0.7605\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 0.8489 Acc: 0.6927\n",
            "val Loss: 0.6395 Acc: 0.7664\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 0.8181 Acc: 0.7007\n",
            "val Loss: 0.6362 Acc: 0.7710\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 0.8113 Acc: 0.7069\n",
            "val Loss: 0.6091 Acc: 0.7792\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 0.7799 Acc: 0.7221\n",
            "val Loss: 0.5943 Acc: 0.8049\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 0.7755 Acc: 0.7191\n",
            "val Loss: 0.5969 Acc: 0.7897\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 0.7433 Acc: 0.7363\n",
            "val Loss: 0.5569 Acc: 0.8026\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 0.7288 Acc: 0.7367\n",
            "val Loss: 0.5753 Acc: 0.8026\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 0.7192 Acc: 0.7426\n",
            "val Loss: 0.5629 Acc: 0.8014\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 0.6981 Acc: 0.7539\n",
            "val Loss: 0.5521 Acc: 0.8084\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 0.6925 Acc: 0.7522\n",
            "val Loss: 0.5976 Acc: 0.8002\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 0.6849 Acc: 0.7578\n",
            "val Loss: 0.5577 Acc: 0.8084\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 0.6727 Acc: 0.7638\n",
            "val Loss: 0.5415 Acc: 0.8271\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 0.6641 Acc: 0.7638\n",
            "val Loss: 0.5298 Acc: 0.8189\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 0.6435 Acc: 0.7689\n",
            "val Loss: 0.5384 Acc: 0.8119\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 0.6535 Acc: 0.7711\n",
            "val Loss: 0.5330 Acc: 0.8224\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 0.6375 Acc: 0.7719\n",
            "val Loss: 0.4938 Acc: 0.8259\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 0.6362 Acc: 0.7705\n",
            "val Loss: 0.4840 Acc: 0.8341\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 0.6288 Acc: 0.7801\n",
            "val Loss: 0.5135 Acc: 0.8201\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 0.6134 Acc: 0.7825\n",
            "val Loss: 0.4939 Acc: 0.8318\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 0.6121 Acc: 0.7829\n",
            "val Loss: 0.4693 Acc: 0.8364\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 0.5968 Acc: 0.7885\n",
            "val Loss: 0.4860 Acc: 0.8364\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 0.6200 Acc: 0.7779\n",
            "val Loss: 0.5385 Acc: 0.8213\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 0.5900 Acc: 0.7913\n",
            "val Loss: 0.4783 Acc: 0.8294\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 0.5861 Acc: 0.7854\n",
            "val Loss: 0.5040 Acc: 0.8423\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 0.5910 Acc: 0.7889\n",
            "val Loss: 0.4630 Acc: 0.8271\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 0.5787 Acc: 0.7942\n",
            "val Loss: 0.4751 Acc: 0.8400\n",
            "\n",
            "Training complete in 70m 49s\n",
            "Best val Acc: 0.842290\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InFNX9KreVYZ",
        "colab_type": "code",
        "outputId": "fbdf488b-eebe-4339-ab3e-1543a4fc2976",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2757
        }
      },
      "source": [
        "model_name = 'densenet'\n",
        "model,_ = initialize_model(model_name, num_classes, feature_extract=False, use_pretrained=False)\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "# Invoke traincall function with the optimizer\n",
        "optimizer_history_scratch[optimizer] = train_model(model, dataloaders_dict, criterion, optimizer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/29\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6029312 bytes but only got 0. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1311848 bytes but only got 785. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:742: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:914: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.9401 Acc: 0.6585\n",
            "val Loss: 0.6983 Acc: 0.7523\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 0.8102 Acc: 0.7056\n",
            "val Loss: 0.5955 Acc: 0.7944\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 0.7347 Acc: 0.7350\n",
            "val Loss: 0.5675 Acc: 0.8061\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 0.6909 Acc: 0.7486\n",
            "val Loss: 0.5599 Acc: 0.8002\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 0.6767 Acc: 0.7550\n",
            "val Loss: 0.5822 Acc: 0.8084\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 0.6327 Acc: 0.7741\n",
            "val Loss: 0.5109 Acc: 0.8259\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 0.6011 Acc: 0.7849\n",
            "val Loss: 0.4787 Acc: 0.8435\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 0.5839 Acc: 0.7923\n",
            "val Loss: 0.4937 Acc: 0.8376\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 0.5688 Acc: 0.7946\n",
            "val Loss: 0.4429 Acc: 0.8505\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 0.5545 Acc: 0.8022\n",
            "val Loss: 0.3927 Acc: 0.8621\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 0.5352 Acc: 0.8127\n",
            "val Loss: 0.4472 Acc: 0.8505\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 0.5192 Acc: 0.8086\n",
            "val Loss: 0.4251 Acc: 0.8598\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 0.5033 Acc: 0.8173\n",
            "val Loss: 0.4160 Acc: 0.8575\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 0.4866 Acc: 0.8209\n",
            "val Loss: 0.4189 Acc: 0.8575\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 0.4838 Acc: 0.8307\n",
            "val Loss: 0.3771 Acc: 0.8668\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 0.4689 Acc: 0.8294\n",
            "val Loss: 0.4197 Acc: 0.8516\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 0.4590 Acc: 0.8373\n",
            "val Loss: 0.3658 Acc: 0.8633\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 0.4477 Acc: 0.8365\n",
            "val Loss: 0.3996 Acc: 0.8621\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 0.4381 Acc: 0.8416\n",
            "val Loss: 0.3735 Acc: 0.8563\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 0.4357 Acc: 0.8438\n",
            "val Loss: 0.4185 Acc: 0.8633\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 0.4249 Acc: 0.8446\n",
            "val Loss: 0.3542 Acc: 0.8773\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 0.4196 Acc: 0.8504\n",
            "val Loss: 0.3544 Acc: 0.8738\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 0.4154 Acc: 0.8501\n",
            "val Loss: 0.3572 Acc: 0.8668\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 0.4006 Acc: 0.8473\n",
            "val Loss: 0.3647 Acc: 0.8692\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 0.3981 Acc: 0.8588\n",
            "val Loss: 0.3663 Acc: 0.8610\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 0.3905 Acc: 0.8605\n",
            "val Loss: 0.3567 Acc: 0.8727\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 0.3762 Acc: 0.8619\n",
            "val Loss: 0.3874 Acc: 0.8645\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 0.3664 Acc: 0.8658\n",
            "val Loss: 0.3775 Acc: 0.8692\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 0.3776 Acc: 0.8645\n",
            "val Loss: 0.3536 Acc: 0.8551\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 0.3663 Acc: 0.8650\n",
            "val Loss: 0.3443 Acc: 0.8808\n",
            "\n",
            "Training complete in 79m 54s\n",
            "Best val Acc: 0.880841\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwYdWbpuCxaY",
        "colab_type": "code",
        "outputId": "de34e315-74ae-41d6-b546-9be3c306d965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2757
        }
      },
      "source": [
        "model_name = 'densenet'\n",
        "model,_ = initialize_model(model_name, num_classes, feature_extract=False, use_pretrained=False)\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adagrad(model.parameters(), lr=0.0001)\n",
        "# Invoke traincall function with the optimizer\n",
        "optimizer_history_scratch[optimizer] = train_model(model, dataloaders_dict, criterion, optimizer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/29\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:914: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6029312 bytes but only got 0. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1311848 bytes but only got 785. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:742: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 1.0659 Acc: 0.6153\n",
            "val Loss: 0.7925 Acc: 0.7336\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 0.9406 Acc: 0.6574\n",
            "val Loss: 0.7287 Acc: 0.7500\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 0.9142 Acc: 0.6727\n",
            "val Loss: 0.7070 Acc: 0.7547\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 0.9046 Acc: 0.6734\n",
            "val Loss: 0.6776 Acc: 0.7617\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 0.8696 Acc: 0.6844\n",
            "val Loss: 0.6723 Acc: 0.7558\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 0.8563 Acc: 0.6946\n",
            "val Loss: 0.6486 Acc: 0.7675\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 0.8528 Acc: 0.6914\n",
            "val Loss: 0.6505 Acc: 0.7605\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 0.8288 Acc: 0.7056\n",
            "val Loss: 0.6378 Acc: 0.7722\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 0.8257 Acc: 0.7021\n",
            "val Loss: 0.6327 Acc: 0.7687\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 0.8172 Acc: 0.7081\n",
            "val Loss: 0.6248 Acc: 0.7780\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 0.8145 Acc: 0.7082\n",
            "val Loss: 0.6277 Acc: 0.7687\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 0.8065 Acc: 0.7073\n",
            "val Loss: 0.6151 Acc: 0.7804\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 0.8010 Acc: 0.7090\n",
            "val Loss: 0.6071 Acc: 0.7722\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 0.7950 Acc: 0.7130\n",
            "val Loss: 0.6129 Acc: 0.7745\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 0.7926 Acc: 0.7197\n",
            "val Loss: 0.6118 Acc: 0.7780\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 0.7847 Acc: 0.7157\n",
            "val Loss: 0.6130 Acc: 0.7874\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 0.7779 Acc: 0.7218\n",
            "val Loss: 0.5940 Acc: 0.7932\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 0.7740 Acc: 0.7227\n",
            "val Loss: 0.5938 Acc: 0.7886\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 0.7660 Acc: 0.7267\n",
            "val Loss: 0.5858 Acc: 0.7921\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 0.7656 Acc: 0.7228\n",
            "val Loss: 0.5724 Acc: 0.7956\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 0.7795 Acc: 0.7200\n",
            "val Loss: 0.5808 Acc: 0.7921\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 0.7576 Acc: 0.7319\n",
            "val Loss: 0.5745 Acc: 0.7850\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 0.7651 Acc: 0.7259\n",
            "val Loss: 0.5831 Acc: 0.7862\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 0.7536 Acc: 0.7265\n",
            "val Loss: 0.5660 Acc: 0.8037\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 0.7532 Acc: 0.7318\n",
            "val Loss: 0.5688 Acc: 0.8002\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 0.7553 Acc: 0.7310\n",
            "val Loss: 0.5855 Acc: 0.7862\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 0.7614 Acc: 0.7285\n",
            "val Loss: 0.5964 Acc: 0.7850\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 0.7422 Acc: 0.7379\n",
            "val Loss: 0.5682 Acc: 0.7956\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 0.7378 Acc: 0.7390\n",
            "val Loss: 0.5736 Acc: 0.7897\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 0.7447 Acc: 0.7368\n",
            "val Loss: 0.5621 Acc: 0.7956\n",
            "\n",
            "Training complete in 72m 23s\n",
            "Best val Acc: 0.803738\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLu9BLaFCxaa",
        "colab_type": "code",
        "outputId": "bf6be69c-df8f-4884-c3db-bf86a186a81d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2757
        }
      },
      "source": [
        "model_name = 'densenet'\n",
        "model,_ = initialize_model(model_name, num_classes, feature_extract=False, use_pretrained=False)\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.RMSprop(model.parameters(), lr=0.0001)\n",
        "# Invoke traincall function with the optimizer\n",
        "optimizer_history_scratch[optimizer] = train_model(model, dataloaders_dict, criterion, optimizer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/29\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6029312 bytes but only got 0. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1311848 bytes but only got 785. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:742: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:914: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.9404 Acc: 0.6463\n",
            "val Loss: 0.8063 Acc: 0.7243\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 0.8142 Acc: 0.7019\n",
            "val Loss: 0.5911 Acc: 0.7886\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 0.7465 Acc: 0.7296\n",
            "val Loss: 0.6513 Acc: 0.7874\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 0.6963 Acc: 0.7504\n",
            "val Loss: 0.5395 Acc: 0.8154\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 0.6588 Acc: 0.7710\n",
            "val Loss: 0.5154 Acc: 0.8411\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 0.6169 Acc: 0.7785\n",
            "val Loss: 0.5158 Acc: 0.8049\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 0.5888 Acc: 0.7853\n",
            "val Loss: 0.4883 Acc: 0.8411\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 0.5956 Acc: 0.7932\n",
            "val Loss: 0.5177 Acc: 0.8166\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 0.5676 Acc: 0.7974\n",
            "val Loss: 0.4571 Acc: 0.8400\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 0.5448 Acc: 0.8095\n",
            "val Loss: 0.4376 Acc: 0.8680\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 0.5331 Acc: 0.8064\n",
            "val Loss: 0.4207 Acc: 0.8493\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 0.5214 Acc: 0.8148\n",
            "val Loss: 0.4432 Acc: 0.8540\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 0.4993 Acc: 0.8217\n",
            "val Loss: 0.4551 Acc: 0.8493\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 0.4952 Acc: 0.8217\n",
            "val Loss: 0.4027 Acc: 0.8575\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 0.4819 Acc: 0.8307\n",
            "val Loss: 0.4390 Acc: 0.8470\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 0.4604 Acc: 0.8328\n",
            "val Loss: 0.3665 Acc: 0.8633\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 0.4549 Acc: 0.8355\n",
            "val Loss: 0.3845 Acc: 0.8610\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 0.4459 Acc: 0.8406\n",
            "val Loss: 0.4300 Acc: 0.8575\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 0.4336 Acc: 0.8430\n",
            "val Loss: 0.4213 Acc: 0.8621\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 0.4362 Acc: 0.8457\n",
            "val Loss: 0.3797 Acc: 0.8750\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 0.4120 Acc: 0.8507\n",
            "val Loss: 0.3774 Acc: 0.8820\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 0.4085 Acc: 0.8535\n",
            "val Loss: 0.3951 Acc: 0.8738\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 0.4090 Acc: 0.8542\n",
            "val Loss: 0.4146 Acc: 0.8586\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 0.3986 Acc: 0.8542\n",
            "val Loss: 0.4055 Acc: 0.8808\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 0.3920 Acc: 0.8569\n",
            "val Loss: 0.3753 Acc: 0.8645\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 0.3872 Acc: 0.8621\n",
            "val Loss: 0.4278 Acc: 0.8563\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 0.3856 Acc: 0.8623\n",
            "val Loss: 0.3335 Acc: 0.8727\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 0.3689 Acc: 0.8669\n",
            "val Loss: 0.3781 Acc: 0.8750\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 0.3809 Acc: 0.8613\n",
            "val Loss: 0.4125 Acc: 0.8843\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 0.3659 Acc: 0.8662\n",
            "val Loss: 0.3300 Acc: 0.8855\n",
            "\n",
            "Training complete in 74m 22s\n",
            "Best val Acc: 0.885514\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCGz5wvpHaAn",
        "colab_type": "code",
        "outputId": "d15178ec-a3d9-414e-ee25-3d0a977bdacb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "optimizer_history_scratch.keys()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys([SGD (\n",
              "Parameter Group 0\n",
              "    dampening: 0\n",
              "    lr: 0.0001\n",
              "    momentum: 0.9\n",
              "    nesterov: False\n",
              "    weight_decay: 0\n",
              "), Adam (\n",
              "Parameter Group 0\n",
              "    amsgrad: False\n",
              "    betas: (0.9, 0.999)\n",
              "    eps: 1e-08\n",
              "    lr: 0.0001\n",
              "    weight_decay: 0\n",
              "), Adagrad (\n",
              "Parameter Group 0\n",
              "    initial_accumulator_value: 0\n",
              "    lr: 0.0001\n",
              "    lr_decay: 0\n",
              "    weight_decay: 0\n",
              "), RMSprop (\n",
              "Parameter Group 0\n",
              "    alpha: 0.99\n",
              "    centered: False\n",
              "    eps: 1e-08\n",
              "    lr: 0.0001\n",
              "    momentum: 0\n",
              "    weight_decay: 0\n",
              ")])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGGflqQ5C9ji",
        "colab_type": "code",
        "outputId": "c11eb2b0-8b34-42fc-9194-554d0f2b2956",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-44df1deea690>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    sgd = [h.cpu().numpy() for h in optimizer_history_scratch[SGD (Parameter Group 0 dampening: 0 lr: 0.0001 momentum: 0.9 nesterov: False weight_decay: 0)]]\u001b[0m\n\u001b[0m                                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fwqPz2MHYfh",
        "colab_type": "code",
        "outputId": "cda89247-4922-4098-985a-205a04628a26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "keys = ['sgd', 'adam', 'adagrad', 'rmsprop']\n",
        "\n",
        "updated_history = {}\n",
        "\n",
        "count = 0\n",
        "\n",
        "for key in optimizer_history_scratch.keys():\n",
        "    print(key)\n",
        "    ls = optimizer_history_scratch[key]\n",
        "    placeholder = []\n",
        "    for l in ls:\n",
        "      value = l.cpu().numpy()\n",
        "      placeholder.append(value)\n",
        "    updated_history[keys[count]] = placeholder\n",
        "    count += 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 0.0001\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.0001\n",
            "    weight_decay: 0\n",
            ")\n",
            "Adagrad (\n",
            "Parameter Group 0\n",
            "    initial_accumulator_value: 0\n",
            "    lr: 0.0001\n",
            "    lr_decay: 0\n",
            "    weight_decay: 0\n",
            ")\n",
            "RMSprop (\n",
            "Parameter Group 0\n",
            "    alpha: 0.99\n",
            "    centered: False\n",
            "    eps: 1e-08\n",
            "    lr: 0.0001\n",
            "    momentum: 0\n",
            "    weight_decay: 0\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0YjeqcXDAPH",
        "colab_type": "code",
        "outputId": "d774dc2f-c3c3-488d-bdce-fa6b63e7b18e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2057
        }
      },
      "source": [
        "updated_history"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'adagrad': [array(0.73364486),\n",
              "  array(0.75),\n",
              "  array(0.7546729),\n",
              "  array(0.76168224),\n",
              "  array(0.75584112),\n",
              "  array(0.76752336),\n",
              "  array(0.76051402),\n",
              "  array(0.77219626),\n",
              "  array(0.76869159),\n",
              "  array(0.77803738),\n",
              "  array(0.76869159),\n",
              "  array(0.78037383),\n",
              "  array(0.77219626),\n",
              "  array(0.77453271),\n",
              "  array(0.77803738),\n",
              "  array(0.78738318),\n",
              "  array(0.7932243),\n",
              "  array(0.7885514),\n",
              "  array(0.79205607),\n",
              "  array(0.79556075),\n",
              "  array(0.79205607),\n",
              "  array(0.78504673),\n",
              "  array(0.78621495),\n",
              "  array(0.80373832),\n",
              "  array(0.80023364),\n",
              "  array(0.78621495),\n",
              "  array(0.78504673),\n",
              "  array(0.79556075),\n",
              "  array(0.78971963),\n",
              "  array(0.79556075)],\n",
              " 'adam': [array(0.75233645),\n",
              "  array(0.79439252),\n",
              "  array(0.80607477),\n",
              "  array(0.80023364),\n",
              "  array(0.80841121),\n",
              "  array(0.82593458),\n",
              "  array(0.84345794),\n",
              "  array(0.83761682),\n",
              "  array(0.85046729),\n",
              "  array(0.86214953),\n",
              "  array(0.85046729),\n",
              "  array(0.85981308),\n",
              "  array(0.85747664),\n",
              "  array(0.85747664),\n",
              "  array(0.86682243),\n",
              "  array(0.85163551),\n",
              "  array(0.86331776),\n",
              "  array(0.86214953),\n",
              "  array(0.85630841),\n",
              "  array(0.86331776),\n",
              "  array(0.87733645),\n",
              "  array(0.87383178),\n",
              "  array(0.86682243),\n",
              "  array(0.86915888),\n",
              "  array(0.86098131),\n",
              "  array(0.87266355),\n",
              "  array(0.86448598),\n",
              "  array(0.86915888),\n",
              "  array(0.85514019),\n",
              "  array(0.88084112)],\n",
              " 'rmsprop': [array(0.72429907),\n",
              "  array(0.7885514),\n",
              "  array(0.78738318),\n",
              "  array(0.81542056),\n",
              "  array(0.8411215),\n",
              "  array(0.80490654),\n",
              "  array(0.8411215),\n",
              "  array(0.81658879),\n",
              "  array(0.83995327),\n",
              "  array(0.86799065),\n",
              "  array(0.84929907),\n",
              "  array(0.85397196),\n",
              "  array(0.84929907),\n",
              "  array(0.85747664),\n",
              "  array(0.84696262),\n",
              "  array(0.86331776),\n",
              "  array(0.86098131),\n",
              "  array(0.85747664),\n",
              "  array(0.86214953),\n",
              "  array(0.875),\n",
              "  array(0.88200935),\n",
              "  array(0.87383178),\n",
              "  array(0.85864486),\n",
              "  array(0.88084112),\n",
              "  array(0.86448598),\n",
              "  array(0.85630841),\n",
              "  array(0.87266355),\n",
              "  array(0.875),\n",
              "  array(0.88434579),\n",
              "  array(0.88551402)],\n",
              " 'sgd': [array(0.69392523),\n",
              "  array(0.73598131),\n",
              "  array(0.75116822),\n",
              "  array(0.76051402),\n",
              "  array(0.76635514),\n",
              "  array(0.77102804),\n",
              "  array(0.77920561),\n",
              "  array(0.80490654),\n",
              "  array(0.78971963),\n",
              "  array(0.80257009),\n",
              "  array(0.80257009),\n",
              "  array(0.80140187),\n",
              "  array(0.80841121),\n",
              "  array(0.80023364),\n",
              "  array(0.80841121),\n",
              "  array(0.8271028),\n",
              "  array(0.81892523),\n",
              "  array(0.81191589),\n",
              "  array(0.82242991),\n",
              "  array(0.82593458),\n",
              "  array(0.83411215),\n",
              "  array(0.82009346),\n",
              "  array(0.8317757),\n",
              "  array(0.8364486),\n",
              "  array(0.8364486),\n",
              "  array(0.82126168),\n",
              "  array(0.82943925),\n",
              "  array(0.84228972),\n",
              "  array(0.8271028),\n",
              "  array(0.83995327)]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKp46CKwDUNx",
        "colab_type": "code",
        "outputId": "e2bbb567-4723-4312-c590-fa748f5b2db8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "sgd = updated_history['sgd']\n",
        "adam = updated_history['adam']\n",
        "adagrad = updated_history['adagrad']\n",
        "rmsprop = updated_history['rmsprop']\n",
        "\n",
        "plt.title(\"Optimizer Training Comparison[Densenet]\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Validation Accuracy\")\n",
        "plt.plot(range(1,num_epochs+1),sgd,label=\"SGD\")\n",
        "plt.plot(range(1,num_epochs+1),adam,label=\"Adam\")\n",
        "plt.plot(range(1,num_epochs+1),adagrad,label=\"Adagrad\")\n",
        "plt.plot(range(1,num_epochs+1),rmsprop,label=\"RMSprop\")\n",
        "\n",
        "plt.ylim((0.65,1.0))\n",
        "plt.xticks(np.arange(1, num_epochs + 1, 2.0))\n",
        "plt.legend()\n",
        "plt.savefig(\"optimizer_training_zoomed.jpg\", bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrCYbeSsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yePhsrTu5T0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8tS2bfK5ezi",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}