{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.0.0\n",
      "Torchvision Version:  0.2.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms\n",
    "# to the ImageFolder structure\n",
    "data_dir = \"E:/data/dataset_updated/\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 5\n",
    "\n",
    "model_name = 'resnet'\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 7\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 30\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "\n",
    "input_size = 224\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pre-trained Network as Feature Extractor\n",
    "\n",
    "We use ['resnet', 'alexnet', 'vgg', 'squeezenet', 'densenet'] as feature extractor and train the final layer for a 7 class classification task. We finally plot the validation accuracies obtained from all the five pre-trained networks over 20 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 0.6233 Acc: 0.7805\n",
      "val Loss: 0.3273 Acc: 0.8703\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.4459 Acc: 0.8389\n",
      "val Loss: 0.2988 Acc: 0.8937\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.4336 Acc: 0.8425\n",
      "val Loss: 0.2939 Acc: 0.8750\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.4189 Acc: 0.8467\n",
      "val Loss: 0.2943 Acc: 0.8902\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.4063 Acc: 0.8483\n",
      "val Loss: 0.2667 Acc: 0.8984\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.4329 Acc: 0.8395\n",
      "val Loss: 0.2723 Acc: 0.8925\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.3925 Acc: 0.8540\n",
      "val Loss: 0.2520 Acc: 0.8949\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.4052 Acc: 0.8513\n",
      "val Loss: 0.2556 Acc: 0.8937\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.4044 Acc: 0.8491\n",
      "val Loss: 0.2591 Acc: 0.8960\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.3807 Acc: 0.8630\n",
      "val Loss: 0.2937 Acc: 0.8902\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.3890 Acc: 0.8592\n",
      "val Loss: 0.3252 Acc: 0.8879\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.4170 Acc: 0.8467\n",
      "val Loss: 0.2780 Acc: 0.8914\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.4013 Acc: 0.8513\n",
      "val Loss: 0.2665 Acc: 0.9019\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.3701 Acc: 0.8625\n",
      "val Loss: 0.3091 Acc: 0.8867\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.3906 Acc: 0.8543\n",
      "val Loss: 0.2899 Acc: 0.8867\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.4007 Acc: 0.8508\n",
      "val Loss: 0.2998 Acc: 0.8843\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.3906 Acc: 0.8551\n",
      "val Loss: 0.2508 Acc: 0.8972\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.3914 Acc: 0.8557\n",
      "val Loss: 0.2705 Acc: 0.8972\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.3985 Acc: 0.8531\n",
      "val Loss: 0.2632 Acc: 0.9019\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.3782 Acc: 0.8613\n",
      "val Loss: 0.2402 Acc: 0.8972\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.3814 Acc: 0.8593\n",
      "val Loss: 0.2538 Acc: 0.8972\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.3919 Acc: 0.8535\n",
      "val Loss: 0.3127 Acc: 0.8797\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.3749 Acc: 0.8623\n",
      "val Loss: 0.2634 Acc: 0.8914\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.3832 Acc: 0.8597\n",
      "val Loss: 0.2504 Acc: 0.8960\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.3922 Acc: 0.8548\n",
      "val Loss: 0.2494 Acc: 0.8960\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.3901 Acc: 0.8583\n",
      "val Loss: 0.2706 Acc: 0.9042\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.3890 Acc: 0.8509\n",
      "val Loss: 0.2665 Acc: 0.8984\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.3985 Acc: 0.8536\n",
      "val Loss: 0.2941 Acc: 0.8855\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.3878 Acc: 0.8556\n",
      "val Loss: 0.3010 Acc: 0.8902\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.3876 Acc: 0.8582\n",
      "val Loss: 0.2713 Acc: 0.8960\n",
      "\n",
      "Training complete in 12m 42s\n",
      "Best val Acc: 0.904206\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 0.4960 Acc: 0.8439\n",
      "val Loss: 0.4419 Acc: 0.8902\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.4482 Acc: 0.8707\n",
      "val Loss: 0.4009 Acc: 0.8960\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.4673 Acc: 0.8667\n",
      "val Loss: 0.3975 Acc: 0.9065\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.4315 Acc: 0.8812\n",
      "val Loss: 0.4541 Acc: 0.8995\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.4220 Acc: 0.8876\n",
      "val Loss: 0.4389 Acc: 0.8855\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.4553 Acc: 0.8840\n",
      "val Loss: 0.4792 Acc: 0.9054\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.4381 Acc: 0.8880\n",
      "val Loss: 0.5305 Acc: 0.9019\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.4438 Acc: 0.8906\n",
      "val Loss: 0.5611 Acc: 0.8972\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.4352 Acc: 0.8906\n",
      "val Loss: 0.5545 Acc: 0.8984\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.4379 Acc: 0.8972\n",
      "val Loss: 0.5045 Acc: 0.9077\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.4211 Acc: 0.9017\n",
      "val Loss: 0.4910 Acc: 0.8972\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.4321 Acc: 0.8972\n",
      "val Loss: 0.4957 Acc: 0.9007\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.4547 Acc: 0.8922\n",
      "val Loss: 0.4568 Acc: 0.9077\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.4084 Acc: 0.9021\n",
      "val Loss: 0.4664 Acc: 0.9054\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.4432 Acc: 0.8994\n",
      "val Loss: 0.5110 Acc: 0.9030\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.4262 Acc: 0.9038\n",
      "val Loss: 0.5382 Acc: 0.9007\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.4614 Acc: 0.8941\n",
      "val Loss: 0.4864 Acc: 0.9054\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.4330 Acc: 0.9004\n",
      "val Loss: 0.4380 Acc: 0.9100\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.4659 Acc: 0.9003\n",
      "val Loss: 0.5268 Acc: 0.9065\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.4721 Acc: 0.8972\n",
      "val Loss: 0.5006 Acc: 0.9112\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.4436 Acc: 0.9045\n",
      "val Loss: 0.5108 Acc: 0.9077\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.4686 Acc: 0.8965\n",
      "val Loss: 0.5747 Acc: 0.9030\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.4675 Acc: 0.8996\n",
      "val Loss: 0.4983 Acc: 0.9171\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.4415 Acc: 0.9004\n",
      "val Loss: 0.5625 Acc: 0.9065\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.4748 Acc: 0.9026\n",
      "val Loss: 0.5873 Acc: 0.8995\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.4389 Acc: 0.9047\n",
      "val Loss: 0.6328 Acc: 0.8925\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.4739 Acc: 0.9044\n",
      "val Loss: 0.6428 Acc: 0.9065\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.4732 Acc: 0.8982\n",
      "val Loss: 0.5972 Acc: 0.8995\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.4818 Acc: 0.9029\n",
      "val Loss: 0.5658 Acc: 0.9042\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.4196 Acc: 0.9117\n",
      "val Loss: 0.6062 Acc: 0.9042\n",
      "\n",
      "Training complete in 11m 4s\n",
      "Best val Acc: 0.917056\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 0.5036 Acc: 0.8136\n",
      "val Loss: 0.2807 Acc: 0.8995\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.4544 Acc: 0.8413\n",
      "val Loss: 0.2527 Acc: 0.9030\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.4465 Acc: 0.8421\n",
      "val Loss: 0.2922 Acc: 0.9065\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.4344 Acc: 0.8529\n",
      "val Loss: 0.2530 Acc: 0.9077\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.4562 Acc: 0.8470\n",
      "val Loss: 0.2771 Acc: 0.9089\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.5003 Acc: 0.8416\n",
      "val Loss: 0.2719 Acc: 0.9007\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.4723 Acc: 0.8512\n",
      "val Loss: 0.2781 Acc: 0.9217\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.4793 Acc: 0.8505\n",
      "val Loss: 0.3066 Acc: 0.9089\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.4924 Acc: 0.8438\n",
      "val Loss: 0.2876 Acc: 0.9112\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.4843 Acc: 0.8509\n",
      "val Loss: 0.2793 Acc: 0.9171\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.4898 Acc: 0.8470\n",
      "val Loss: 0.3346 Acc: 0.8890\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.4905 Acc: 0.8461\n",
      "val Loss: 0.4124 Acc: 0.8902\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.5075 Acc: 0.8500\n",
      "val Loss: 0.2799 Acc: 0.9112\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.4691 Acc: 0.8557\n",
      "val Loss: 0.2598 Acc: 0.9159\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.4651 Acc: 0.8561\n",
      "val Loss: 0.2967 Acc: 0.9136\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.4861 Acc: 0.8531\n",
      "val Loss: 0.3345 Acc: 0.8984\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.5275 Acc: 0.8492\n",
      "val Loss: 0.3343 Acc: 0.8949\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.5041 Acc: 0.8514\n",
      "val Loss: 0.2749 Acc: 0.9077\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.5018 Acc: 0.8558\n",
      "val Loss: 0.2930 Acc: 0.9112\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.5180 Acc: 0.8474\n",
      "val Loss: 0.2887 Acc: 0.9019\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.5058 Acc: 0.8526\n",
      "val Loss: 0.3018 Acc: 0.9007\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.4968 Acc: 0.8580\n",
      "val Loss: 0.2839 Acc: 0.9206\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.5091 Acc: 0.8526\n",
      "val Loss: 0.2962 Acc: 0.9077\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.5118 Acc: 0.8531\n",
      "val Loss: 0.2872 Acc: 0.8972\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.4956 Acc: 0.8543\n",
      "val Loss: 0.3268 Acc: 0.8949\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.5169 Acc: 0.8580\n",
      "val Loss: 0.3321 Acc: 0.8995\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.5475 Acc: 0.8439\n",
      "val Loss: 0.2833 Acc: 0.9136\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.5247 Acc: 0.8536\n",
      "val Loss: 0.2810 Acc: 0.9112\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.5288 Acc: 0.8500\n",
      "val Loss: 0.3179 Acc: 0.9089\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.4997 Acc: 0.8557\n",
      "val Loss: 0.3298 Acc: 0.9112\n",
      "\n",
      "Training complete in 31m 1s\n",
      "Best val Acc: 0.921729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Parth Pankaj Tiwary\\Anaconda2\\envs\\torch\\lib\\site-packages\\torchvision\\models\\squeezenet.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
      "  init.kaiming_uniform(m.weight.data)\n",
      "C:\\Users\\Parth Pankaj Tiwary\\Anaconda2\\envs\\torch\\lib\\site-packages\\torchvision\\models\\squeezenet.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  init.normal(m.weight.data, mean=0.0, std=0.01)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 0.4597 Acc: 0.8360\n",
      "val Loss: 0.2958 Acc: 0.8867\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.3182 Acc: 0.8840\n",
      "val Loss: 0.2717 Acc: 0.9054\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.2840 Acc: 0.8976\n",
      "val Loss: 0.2588 Acc: 0.9124\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.2981 Acc: 0.8915\n",
      "val Loss: 0.2485 Acc: 0.9264\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.2766 Acc: 0.8982\n",
      "val Loss: 0.2803 Acc: 0.8937\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.2745 Acc: 0.8969\n",
      "val Loss: 0.2404 Acc: 0.9100\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.2740 Acc: 0.8983\n",
      "val Loss: 0.2255 Acc: 0.9217\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.2604 Acc: 0.8991\n",
      "val Loss: 0.2244 Acc: 0.9124\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.2612 Acc: 0.9034\n",
      "val Loss: 0.2461 Acc: 0.9206\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.2628 Acc: 0.9022\n",
      "val Loss: 0.2388 Acc: 0.9100\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.2570 Acc: 0.9082\n",
      "val Loss: 0.2728 Acc: 0.9217\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.2508 Acc: 0.9030\n",
      "val Loss: 0.2397 Acc: 0.9241\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.2570 Acc: 0.9030\n",
      "val Loss: 0.2180 Acc: 0.9171\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.2475 Acc: 0.9080\n",
      "val Loss: 0.2265 Acc: 0.9194\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.2577 Acc: 0.9075\n",
      "val Loss: 0.2592 Acc: 0.9100\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.2485 Acc: 0.9057\n",
      "val Loss: 0.2419 Acc: 0.9159\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.2460 Acc: 0.9130\n",
      "val Loss: 0.2365 Acc: 0.9147\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.2536 Acc: 0.9086\n",
      "val Loss: 0.2423 Acc: 0.9171\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.2408 Acc: 0.9104\n",
      "val Loss: 0.2359 Acc: 0.9206\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.2487 Acc: 0.9087\n",
      "val Loss: 0.2472 Acc: 0.9182\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.2496 Acc: 0.9077\n",
      "val Loss: 0.2375 Acc: 0.9171\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.2532 Acc: 0.9070\n",
      "val Loss: 0.2413 Acc: 0.9147\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.2484 Acc: 0.9073\n",
      "val Loss: 0.2315 Acc: 0.9159\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.2414 Acc: 0.9092\n",
      "val Loss: 0.2558 Acc: 0.9159\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.2522 Acc: 0.9069\n",
      "val Loss: 0.2523 Acc: 0.9124\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.2503 Acc: 0.9099\n",
      "val Loss: 0.2329 Acc: 0.9206\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.2417 Acc: 0.9102\n",
      "val Loss: 0.2526 Acc: 0.9147\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.2460 Acc: 0.9095\n",
      "val Loss: 0.2390 Acc: 0.9159\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.2450 Acc: 0.9077\n",
      "val Loss: 0.2317 Acc: 0.9206\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.2463 Acc: 0.9062\n",
      "val Loss: 0.2396 Acc: 0.9182\n",
      "\n",
      "Training complete in 11m 7s\n",
      "Best val Acc: 0.926402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Parth Pankaj Tiwary\\Anaconda2\\envs\\torch\\lib\\site-packages\\torchvision\\models\\densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 0.5911 Acc: 0.7974\n",
      "val Loss: 0.3016 Acc: 0.9019\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.4018 Acc: 0.8566\n",
      "val Loss: 0.2537 Acc: 0.9112\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.3932 Acc: 0.8566\n",
      "val Loss: 0.2357 Acc: 0.9194\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.3709 Acc: 0.8666\n",
      "val Loss: 0.2544 Acc: 0.9159\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.3627 Acc: 0.8661\n",
      "val Loss: 0.2247 Acc: 0.9229\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.3608 Acc: 0.8679\n",
      "val Loss: 0.2192 Acc: 0.9217\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.3609 Acc: 0.8671\n",
      "val Loss: 0.2417 Acc: 0.9100\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.3542 Acc: 0.8735\n",
      "val Loss: 0.2011 Acc: 0.9322\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.3300 Acc: 0.8808\n",
      "val Loss: 0.1991 Acc: 0.9241\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.3495 Acc: 0.8679\n",
      "val Loss: 0.2215 Acc: 0.9206\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.3406 Acc: 0.8755\n",
      "val Loss: 0.1945 Acc: 0.9276\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.3371 Acc: 0.8814\n",
      "val Loss: 0.2241 Acc: 0.9136\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.3382 Acc: 0.8770\n",
      "val Loss: 0.2022 Acc: 0.9229\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.3387 Acc: 0.8775\n",
      "val Loss: 0.2224 Acc: 0.9206\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.3360 Acc: 0.8810\n",
      "val Loss: 0.2203 Acc: 0.9229\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.3391 Acc: 0.8723\n",
      "val Loss: 0.2170 Acc: 0.9182\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.3318 Acc: 0.8785\n",
      "val Loss: 0.2006 Acc: 0.9241\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.3271 Acc: 0.8803\n",
      "val Loss: 0.2272 Acc: 0.9182\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.3229 Acc: 0.8838\n",
      "val Loss: 0.2276 Acc: 0.9241\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.3402 Acc: 0.8771\n",
      "val Loss: 0.2269 Acc: 0.9159\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.3379 Acc: 0.8785\n",
      "val Loss: 0.2592 Acc: 0.9030\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.3214 Acc: 0.8860\n",
      "val Loss: 0.2296 Acc: 0.9217\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.3298 Acc: 0.8824\n",
      "val Loss: 0.2093 Acc: 0.9264\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.3427 Acc: 0.8783\n",
      "val Loss: 0.2602 Acc: 0.9042\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.3251 Acc: 0.8840\n",
      "val Loss: 0.2258 Acc: 0.9159\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.3161 Acc: 0.8878\n",
      "val Loss: 0.1927 Acc: 0.9334\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.3220 Acc: 0.8818\n",
      "val Loss: 0.2166 Acc: 0.9264\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.3272 Acc: 0.8834\n",
      "val Loss: 0.2269 Acc: 0.9159\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.3288 Acc: 0.8798\n",
      "val Loss: 0.2139 Acc: 0.9206\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.3373 Acc: 0.8777\n",
      "val Loss: 0.2349 Acc: 0.9182\n",
      "\n",
      "Training complete in 27m 44s\n",
      "Best val Acc: 0.933411\n"
     ]
    }
   ],
   "source": [
    "## basically, we loop through each model in the model_list\n",
    "\n",
    "model_list = ['resnet', 'alexnet', 'vgg', 'squeezenet', 'densenet']\n",
    "acc_history = {}\n",
    "for model_name in model_list:\n",
    "    # Initialize the non-pretrained version of the model used for this run\n",
    "    model,_ = initialize_model(model_name, num_classes, feature_extract=True, use_pretrained=True)\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    _, acc_history[model_name] = train_model(model, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "# of training epochs for the transfer learning method and\n",
    "# the model trained from scratch\n",
    "resnet = []\n",
    "alexnet = []\n",
    "vgg = []\n",
    "squeezenet = []\n",
    "densenet = []\n",
    "\n",
    "resnet = [h.cpu().numpy() for h in acc_history['resnet']]\n",
    "alexnet = [h.cpu().numpy() for h in acc_history['alexnet']]\n",
    "vgg = [h.cpu().numpy() for h in acc_history['vgg']]\n",
    "squeezenet = [h.cpu().numpy() for h in acc_history['squeezenet']]\n",
    "densenet = [h.cpu().numpy() for h in acc_history['densenet']]\n",
    "\n",
    "plt.title(\"Validation Accuracy vs. Epochs[Feature Extraction]\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),resnet,label=\"Resnet\")\n",
    "plt.plot(range(1,num_epochs+1),alexnet,label=\"Alexnet\")\n",
    "plt.plot(range(1,num_epochs+1),vgg,label=\"VGG\")\n",
    "plt.plot(range(1,num_epochs+1),squeezenet,label=\"Squeezenet\")\n",
    "plt.plot(range(1,num_epochs+1),densenet,label=\"Densenet\")\n",
    "# plt.plot(range(1,num_epochs+1),inception,label=\"Inception\")\n",
    "plt.ylim((0.8, 1.))\n",
    "plt.xticks(np.arange(1, num_epochs + 1, 2.0))\n",
    "plt.legend()\n",
    "plt.savefig(\"feature_extractor_zoomed_in.jpg\", bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.savefig(\"feature_extractor.jpg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Pre-trained Network from Scratch\n",
    "\n",
    "We use ['resnet', 'alexnet', 'vgg', 'squeezenet', 'densenet'] and train them from scratch for a 7 class classification task. We finally plot the validation accuracies obtained from all the five pre-trained networks over 20 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.0954 Acc: 0.5822\n",
      "val Loss: 0.6812 Acc: 0.7582\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.9496 Acc: 0.6507\n",
      "val Loss: 0.6426 Acc: 0.7745\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.8658 Acc: 0.6873\n",
      "val Loss: 0.6074 Acc: 0.7886\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.8186 Acc: 0.7051\n",
      "val Loss: 0.6671 Acc: 0.7640\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.7629 Acc: 0.7179\n",
      "val Loss: 0.5779 Acc: 0.7932\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.7049 Acc: 0.7428\n",
      "val Loss: 0.5588 Acc: 0.8037\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.6762 Acc: 0.7574\n",
      "val Loss: 0.5819 Acc: 0.8061\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.6766 Acc: 0.7565\n",
      "val Loss: 0.5055 Acc: 0.8248\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.6476 Acc: 0.7665\n",
      "val Loss: 0.6565 Acc: 0.7769\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.6140 Acc: 0.7822\n",
      "val Loss: 0.4952 Acc: 0.8271\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.6025 Acc: 0.7834\n",
      "val Loss: 0.4760 Acc: 0.8388\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.5797 Acc: 0.7917\n",
      "val Loss: 0.5318 Acc: 0.8201\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.5730 Acc: 0.7899\n",
      "val Loss: 0.4703 Acc: 0.8213\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.5597 Acc: 0.7986\n",
      "val Loss: 0.4750 Acc: 0.8470\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.5283 Acc: 0.8048\n",
      "val Loss: 0.3951 Acc: 0.8575\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.5315 Acc: 0.8052\n",
      "val Loss: 0.4432 Acc: 0.8423\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.5078 Acc: 0.8135\n",
      "val Loss: 0.3892 Acc: 0.8493\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.5004 Acc: 0.8174\n",
      "val Loss: 0.4343 Acc: 0.8481\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.5074 Acc: 0.8147\n",
      "val Loss: 0.4208 Acc: 0.8470\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.4919 Acc: 0.8197\n",
      "val Loss: 0.4661 Acc: 0.8411\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.4744 Acc: 0.8259\n",
      "val Loss: 0.4424 Acc: 0.8540\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.4846 Acc: 0.8198\n",
      "val Loss: 0.4266 Acc: 0.8411\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.4617 Acc: 0.8311\n",
      "val Loss: 0.4142 Acc: 0.8540\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.4524 Acc: 0.8358\n",
      "val Loss: 0.3754 Acc: 0.8633\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.4478 Acc: 0.8393\n",
      "val Loss: 0.3807 Acc: 0.8528\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.4471 Acc: 0.8422\n",
      "val Loss: 0.3806 Acc: 0.8610\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.4293 Acc: 0.8382\n",
      "val Loss: 0.3444 Acc: 0.8703\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.4335 Acc: 0.8389\n",
      "val Loss: 0.3861 Acc: 0.8610\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.4360 Acc: 0.8424\n",
      "val Loss: 0.3858 Acc: 0.8505\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.4138 Acc: 0.8479\n",
      "val Loss: 0.3719 Acc: 0.8586\n",
      "\n",
      "Training complete in 33m 31s\n",
      "Best val Acc: 0.870327\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.2744 Acc: 0.4514\n",
      "val Loss: 1.0072 Acc: 0.5958\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.9977 Acc: 0.6105\n",
      "val Loss: 0.8302 Acc: 0.6974\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.9143 Acc: 0.6599\n",
      "val Loss: 0.8853 Acc: 0.6776\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.8618 Acc: 0.6868\n",
      "val Loss: 0.6822 Acc: 0.7570\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.7863 Acc: 0.7206\n",
      "val Loss: 0.6692 Acc: 0.7442\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.7371 Acc: 0.7353\n",
      "val Loss: 0.6446 Acc: 0.7675\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.7092 Acc: 0.7442\n",
      "val Loss: 0.6064 Acc: 0.7734\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.6640 Acc: 0.7639\n",
      "val Loss: 0.5586 Acc: 0.8119\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.6454 Acc: 0.7704\n",
      "val Loss: 0.6108 Acc: 0.7687\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.6385 Acc: 0.7693\n",
      "val Loss: 0.5565 Acc: 0.7862\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.6031 Acc: 0.7805\n",
      "val Loss: 0.5154 Acc: 0.7967\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.5907 Acc: 0.7869\n",
      "val Loss: 0.5238 Acc: 0.7991\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.5715 Acc: 0.7981\n",
      "val Loss: 0.5534 Acc: 0.7991\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.5583 Acc: 0.7947\n",
      "val Loss: 0.5836 Acc: 0.7815\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.5578 Acc: 0.7986\n",
      "val Loss: 0.4851 Acc: 0.8014\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.5313 Acc: 0.8081\n",
      "val Loss: 0.4477 Acc: 0.8376\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.5296 Acc: 0.8075\n",
      "val Loss: 0.4280 Acc: 0.8423\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.5140 Acc: 0.8101\n",
      "val Loss: 0.4760 Acc: 0.8201\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.5022 Acc: 0.8132\n",
      "val Loss: 0.4775 Acc: 0.8189\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.4952 Acc: 0.8178\n",
      "val Loss: 0.4399 Acc: 0.8306\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.4842 Acc: 0.8226\n",
      "val Loss: 0.4207 Acc: 0.8435\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.4806 Acc: 0.8253\n",
      "val Loss: 0.4026 Acc: 0.8446\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.4623 Acc: 0.8307\n",
      "val Loss: 0.4302 Acc: 0.8353\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.4645 Acc: 0.8307\n",
      "val Loss: 0.4089 Acc: 0.8435\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.4579 Acc: 0.8353\n",
      "val Loss: 0.4385 Acc: 0.8294\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.4565 Acc: 0.8301\n",
      "val Loss: 0.4310 Acc: 0.8236\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.4386 Acc: 0.8349\n",
      "val Loss: 0.4253 Acc: 0.8236\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.4334 Acc: 0.8393\n",
      "val Loss: 0.3879 Acc: 0.8563\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.4345 Acc: 0.8404\n",
      "val Loss: 0.3824 Acc: 0.8505\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.4292 Acc: 0.8426\n",
      "val Loss: 0.4272 Acc: 0.8388\n",
      "\n",
      "Training complete in 24m 59s\n",
      "Best val Acc: 0.856308\n",
      "Epoch 0/29\n",
      "----------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 3.00 GiB total capacity; 1.80 GiB already allocated; 211.49 MiB free; 60.89 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-840dc5252e03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_history_scratch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloaders_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_inception\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"inception\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-391d22e8ca1a>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloaders, criterion, optimizer, num_epochs, is_inception)\u001b[0m\n\u001b[0;32m     50\u001b[0m                     \u001b[1;31m# backward + optimize only if in training phase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m                         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\torch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\torch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 3.00 GiB total capacity; 1.80 GiB already allocated; 211.49 MiB free; 60.89 MiB cached)"
     ]
    }
   ],
   "source": [
    "## basically, we loop through each model in the model_list\n",
    "\n",
    "model_list = ['resnet', 'alexnet']\n",
    "acc_history_scratch = {}\n",
    "for model_name in model_list:\n",
    "    # Initialize the non-pretrained version of the model used for this run\n",
    "    model,_ = initialize_model(model_name, num_classes, feature_extract=False, use_pretrained=False)\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    _, acc_history_scratch[model_name] = train_model(model, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))\n",
    "    torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = ['vgg', 'squeezenet', 'densenet']\n",
    "acc_history_scratch = {}\n",
    "for model_name in model_list:\n",
    "    # Initialize the non-pretrained version of the model used for this run\n",
    "    model,_ = initialize_model(model_name, num_classes, feature_extract=False, use_pretrained=False)\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    _, acc_history_scratch[model_name] = train_model(model, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))\n",
    "    torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "# of training epochs for the transfer learning method and\n",
    "# the model trained from scratch\n",
    "resnet = []\n",
    "alexnet = []\n",
    "vgg = []\n",
    "squeezenet = []\n",
    "densenet = []\n",
    "\n",
    "resnet = [h.cpu().numpy() for h in acc_history_scratch['resnet']]\n",
    "alexnet = [h.cpu().numpy() for h in acc_history_scratch['alexnet']]\n",
    "vgg = [h.cpu().numpy() for h in acc_history_scratch['vgg']]\n",
    "squeezenet = [h.cpu().numpy() for h in acc_history_scratch['squeezenet']]\n",
    "densenet = [h.cpu().numpy() for h in acc_history_scratch['densenet']]\n",
    "\n",
    "plt.title(\"Validation Accuracy vs. Epochs[Scratch]\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),resnet,label=\"Resnet\")\n",
    "plt.plot(range(1,num_epochs+1),alexnet,label=\"Alexnet\")\n",
    "plt.plot(range(1,num_epochs+1),vgg,label=\"VGG\")\n",
    "plt.plot(range(1,num_epochs+1),squeezenet,label=\"Squeezenet\")\n",
    "plt.plot(range(1,num_epochs+1),densenet,label=\"Densenet\")\n",
    "# plt.plot(range(1,num_epochs+1),inception,label=\"Inception\")\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1, num_epochs + 1, 2.0))\n",
    "plt.legend()\n",
    "lt.savefig(\"scratch_training.jpg\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
