{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.0.0\n",
      "Torchvision Version:  0.2.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms\n",
    "# to the ImageFolder structure\n",
    "data_dir = \"E:/minc-2500/data\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 7\n",
    "\n",
    "model_name = 'resnet'\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 20\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 20\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=512, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pre-trained Network as Feature Extractor\n",
    "\n",
    "We use ['resnet', 'alexnet', 'vgg', 'squeezenet', 'densenet'] as feature extractor and train the final layer for a 7 class classification task. We finally plot the validation accuracies obtained from all the five pre-trained networks over 20 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 1.2751 Acc: 0.6463\n",
      "val Loss: 1.1070 Acc: 0.7071\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.3106 Acc: 0.6718\n",
      "val Loss: 1.3265 Acc: 0.6786\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 1.3440 Acc: 0.6715\n",
      "val Loss: 1.5868 Acc: 0.7071\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 1.3096 Acc: 0.6793\n",
      "val Loss: 1.1274 Acc: 0.7214\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 1.3504 Acc: 0.6749\n",
      "val Loss: 1.3650 Acc: 0.6929\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 1.2661 Acc: 0.6840\n",
      "val Loss: 1.2047 Acc: 0.6714\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 1.2800 Acc: 0.6728\n",
      "val Loss: 1.7537 Acc: 0.7286\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 1.3074 Acc: 0.6768\n",
      "val Loss: 1.2522 Acc: 0.7214\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.3159 Acc: 0.6779\n",
      "val Loss: 1.2459 Acc: 0.7214\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 1.3033 Acc: 0.6810\n",
      "val Loss: 1.3436 Acc: 0.7000\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 1.2840 Acc: 0.6838\n",
      "val Loss: 1.2254 Acc: 0.7357\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 1.3185 Acc: 0.6791\n",
      "val Loss: 1.3093 Acc: 0.6857\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 1.2970 Acc: 0.6801\n",
      "val Loss: 1.4720 Acc: 0.7571\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 1.2454 Acc: 0.6799\n",
      "val Loss: 1.5294 Acc: 0.7000\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 1.3333 Acc: 0.6741\n",
      "val Loss: 1.0522 Acc: 0.7357\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 1.2732 Acc: 0.6852\n",
      "val Loss: 1.2719 Acc: 0.7500\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 1.2926 Acc: 0.6735\n",
      "val Loss: 1.1788 Acc: 0.7143\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 1.3215 Acc: 0.6762\n",
      "val Loss: 1.7990 Acc: 0.6286\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 1.2780 Acc: 0.6819\n",
      "val Loss: 1.2306 Acc: 0.7071\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 1.2555 Acc: 0.6884\n",
      "val Loss: 1.1356 Acc: 0.7071\n",
      "\n",
      "Training complete in 12m 48s\n",
      "Best val Acc: 0.757143\n",
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 4.3076 Acc: 0.6154\n",
      "val Loss: 3.7396 Acc: 0.6643\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 4.8100 Acc: 0.6475\n",
      "val Loss: 5.4775 Acc: 0.6714\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 4.8535 Acc: 0.6616\n",
      "val Loss: 4.7877 Acc: 0.7071\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 4.8234 Acc: 0.6626\n",
      "val Loss: 4.0552 Acc: 0.7071\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 4.9462 Acc: 0.6692\n",
      "val Loss: 4.2920 Acc: 0.6857\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 5.0032 Acc: 0.6684\n",
      "val Loss: 4.7897 Acc: 0.7000\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 5.0784 Acc: 0.6739\n",
      "val Loss: 5.5052 Acc: 0.7214\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 4.9952 Acc: 0.6749\n",
      "val Loss: 4.5267 Acc: 0.7214\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 5.0538 Acc: 0.6756\n",
      "val Loss: 5.0713 Acc: 0.7000\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 5.1946 Acc: 0.6730\n",
      "val Loss: 4.1668 Acc: 0.7357\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 4.9977 Acc: 0.6768\n",
      "val Loss: 3.9230 Acc: 0.7357\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 4.9744 Acc: 0.6809\n",
      "val Loss: 4.1534 Acc: 0.6786\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 5.0630 Acc: 0.6779\n",
      "val Loss: 4.7476 Acc: 0.7071\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 5.1113 Acc: 0.6826\n",
      "val Loss: 4.4696 Acc: 0.7500\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 5.1514 Acc: 0.6832\n",
      "val Loss: 4.8992 Acc: 0.7357\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 5.0797 Acc: 0.6850\n",
      "val Loss: 5.2792 Acc: 0.7071\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 5.0936 Acc: 0.6820\n",
      "val Loss: 4.6288 Acc: 0.7500\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 5.0061 Acc: 0.6904\n",
      "val Loss: 5.6218 Acc: 0.7143\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 5.1211 Acc: 0.6825\n",
      "val Loss: 4.7590 Acc: 0.7429\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 5.1560 Acc: 0.6853\n",
      "val Loss: 4.9095 Acc: 0.7500\n",
      "\n",
      "Training complete in 10m 58s\n",
      "Best val Acc: 0.750000\n",
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 1.4336 Acc: 0.6373\n",
      "val Loss: 1.2840 Acc: 0.7071\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.7223 Acc: 0.6480\n",
      "val Loss: 1.8449 Acc: 0.6857\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 1.8142 Acc: 0.6618\n",
      "val Loss: 1.3393 Acc: 0.7429\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 1.9134 Acc: 0.6573\n",
      "val Loss: 1.3970 Acc: 0.7000\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 1.8996 Acc: 0.6639\n",
      "val Loss: 1.4557 Acc: 0.7429\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 1.9692 Acc: 0.6617\n",
      "val Loss: 1.6119 Acc: 0.7143\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 1.9824 Acc: 0.6628\n",
      "val Loss: 1.3717 Acc: 0.7357\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 2.0161 Acc: 0.6601\n",
      "val Loss: 1.5019 Acc: 0.7214\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.9940 Acc: 0.6646\n",
      "val Loss: 1.6761 Acc: 0.7500\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 2.0090 Acc: 0.6645\n",
      "val Loss: 1.6245 Acc: 0.7357\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 1.9808 Acc: 0.6699\n",
      "val Loss: 1.9198 Acc: 0.6929\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 2.0313 Acc: 0.6660\n",
      "val Loss: 1.4792 Acc: 0.7286\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 2.0510 Acc: 0.6601\n",
      "val Loss: 1.5551 Acc: 0.7071\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 2.0125 Acc: 0.6661\n",
      "val Loss: 1.5206 Acc: 0.7286\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 2.0734 Acc: 0.6624\n",
      "val Loss: 1.4796 Acc: 0.7500\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 2.0688 Acc: 0.6627\n",
      "val Loss: 1.5604 Acc: 0.7143\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 2.0538 Acc: 0.6694\n",
      "val Loss: 1.4771 Acc: 0.7500\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 1.9833 Acc: 0.6695\n",
      "val Loss: 1.8124 Acc: 0.7071\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 2.0542 Acc: 0.6617\n",
      "val Loss: 1.2948 Acc: 0.7429\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 2.0138 Acc: 0.6700\n",
      "val Loss: 1.5611 Acc: 0.7357\n",
      "\n",
      "Training complete in 55m 10s\n",
      "Best val Acc: 0.750000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Parth Pankaj Tiwary\\Anaconda2\\envs\\torch\\lib\\site-packages\\torchvision\\models\\squeezenet.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
      "  init.kaiming_uniform(m.weight.data)\n",
      "C:\\Users\\Parth Pankaj Tiwary\\Anaconda2\\envs\\torch\\lib\\site-packages\\torchvision\\models\\squeezenet.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  init.normal(m.weight.data, mean=0.0, std=0.01)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 0.9975 Acc: 0.6809\n",
      "val Loss: 0.8781 Acc: 0.7214\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 0.8973 Acc: 0.7144\n",
      "val Loss: 0.7928 Acc: 0.7357\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 0.8687 Acc: 0.7219\n",
      "val Loss: 0.8348 Acc: 0.7357\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 0.8434 Acc: 0.7328\n",
      "val Loss: 0.8456 Acc: 0.7286\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 0.8421 Acc: 0.7337\n",
      "val Loss: 0.8172 Acc: 0.7500\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 0.8234 Acc: 0.7303\n",
      "val Loss: 0.8376 Acc: 0.7143\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 0.8272 Acc: 0.7385\n",
      "val Loss: 0.7901 Acc: 0.7714\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 0.8284 Acc: 0.7346\n",
      "val Loss: 0.8025 Acc: 0.7000\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 0.8236 Acc: 0.7366\n",
      "val Loss: 0.8441 Acc: 0.7214\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 0.7999 Acc: 0.7411\n",
      "val Loss: 0.8002 Acc: 0.7357\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 0.8184 Acc: 0.7368\n",
      "val Loss: 0.7445 Acc: 0.7571\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 0.8187 Acc: 0.7368\n",
      "val Loss: 0.8113 Acc: 0.7286\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 0.8190 Acc: 0.7385\n",
      "val Loss: 0.8149 Acc: 0.7500\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 0.8019 Acc: 0.7444\n",
      "val Loss: 0.8478 Acc: 0.7286\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 0.8080 Acc: 0.7395\n",
      "val Loss: 0.7403 Acc: 0.7357\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 0.7967 Acc: 0.7418\n",
      "val Loss: 0.7802 Acc: 0.7286\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 0.8023 Acc: 0.7392\n",
      "val Loss: 0.8961 Acc: 0.7286\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 0.8017 Acc: 0.7430\n",
      "val Loss: 0.8279 Acc: 0.7071\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 0.7919 Acc: 0.7450\n",
      "val Loss: 0.8625 Acc: 0.7000\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 0.8014 Acc: 0.7417\n",
      "val Loss: 0.8102 Acc: 0.7643\n",
      "\n",
      "Training complete in 61m 12s\n",
      "Best val Acc: 0.771429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Parth Pankaj Tiwary\\Anaconda2\\envs\\torch\\lib\\site-packages\\torchvision\\models\\densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 1.2575 Acc: 0.6590\n",
      "val Loss: 1.0500 Acc: 0.7357\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.2055 Acc: 0.6942\n",
      "val Loss: 1.2753 Acc: 0.7071\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 1.1984 Acc: 0.7026\n",
      "val Loss: 1.1511 Acc: 0.7286\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 1.1987 Acc: 0.7029\n",
      "val Loss: 1.2181 Acc: 0.6643\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 1.1899 Acc: 0.6994\n",
      "val Loss: 1.1277 Acc: 0.7571\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 1.1763 Acc: 0.7086\n",
      "val Loss: 1.1247 Acc: 0.7286\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 1.1829 Acc: 0.7048\n",
      "val Loss: 1.1883 Acc: 0.6857\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 1.2197 Acc: 0.7006\n",
      "val Loss: 1.0462 Acc: 0.7429\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.1749 Acc: 0.7127\n",
      "val Loss: 1.2735 Acc: 0.7000\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 1.1754 Acc: 0.7078\n",
      "val Loss: 1.2770 Acc: 0.7429\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 1.1612 Acc: 0.7091\n",
      "val Loss: 1.3082 Acc: 0.7286\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 1.2495 Acc: 0.7000\n",
      "val Loss: 0.9527 Acc: 0.7500\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 1.1344 Acc: 0.7113\n",
      "val Loss: 0.9608 Acc: 0.7714\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 1.1693 Acc: 0.7071\n",
      "val Loss: 1.1180 Acc: 0.7214\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 1.2526 Acc: 0.7006\n",
      "val Loss: 1.1586 Acc: 0.7500\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 1.2653 Acc: 0.6979\n",
      "val Loss: 0.9758 Acc: 0.7500\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 1.2179 Acc: 0.7123\n",
      "val Loss: 1.1714 Acc: 0.7714\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 1.1617 Acc: 0.7118\n",
      "val Loss: 0.9679 Acc: 0.7857\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 1.1944 Acc: 0.7079\n",
      "val Loss: 0.9407 Acc: 0.7786\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 1.1900 Acc: 0.7090\n",
      "val Loss: 1.2343 Acc: 0.7357\n",
      "\n",
      "Training complete in 79m 27s\n",
      "Best val Acc: 0.785714\n"
     ]
    }
   ],
   "source": [
    "## basically, we loop through each model in the model_list\n",
    "\n",
    "model_list = ['resnet', 'alexnet', 'vgg', 'squeezenet', 'densenet']\n",
    "acc_history = {}\n",
    "for model_name in model_list:\n",
    "    # Initialize the non-pretrained version of the model used for this run\n",
    "    model,_ = initialize_model(model_name, num_classes, feature_extract=True, use_pretrained=True)\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    _, acc_history[model_name] = train_model(model, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "# of training epochs for the transfer learning method and\n",
    "# the model trained from scratch\n",
    "resnet = []\n",
    "alexnet = []\n",
    "vgg = []\n",
    "squeezenet = []\n",
    "densenet = []\n",
    "\n",
    "resnet = [h.cpu().numpy() for h in acc_history['resnet']]\n",
    "alexnet = [h.cpu().numpy() for h in acc_history['alexnet']]\n",
    "vgg = [h.cpu().numpy() for h in acc_history['vgg']]\n",
    "squeezenet = [h.cpu().numpy() for h in acc_history['squeezenet']]\n",
    "densenet = [h.cpu().numpy() for h in acc_history['densenet']]\n",
    "\n",
    "plt.title(\"Validation Accuracy vs. Epochs[Feature Extraction]\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),resnet,label=\"Resnet\")\n",
    "plt.plot(range(1,num_epochs+1),alexnet,label=\"Alexnet\")\n",
    "plt.plot(range(1,num_epochs+1),vgg,label=\"VGG\")\n",
    "plt.plot(range(1,num_epochs+1),squeezenet,label=\"Squeezenet\")\n",
    "plt.plot(range(1,num_epochs+1),densenet,label=\"Densenet\")\n",
    "# plt.plot(range(1,num_epochs+1),inception,label=\"Inception\")\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Pre-trained Network from Scratch\n",
    "\n",
    "We use ['resnet', 'alexnet', 'vgg', 'squeezenet', 'densenet'] and train them from scratch for a 7 class classification task. We finally plot the validation accuracies obtained from all the five pre-trained networks over 20 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 1.7579 Acc: 0.3361\n",
      "val Loss: 1.5786 Acc: 0.3929\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.4985 Acc: 0.4429\n",
      "val Loss: 1.4458 Acc: 0.4357\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 1.3879 Acc: 0.4944\n",
      "val Loss: 1.3911 Acc: 0.4714\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 1.3137 Acc: 0.5211\n",
      "val Loss: 1.2908 Acc: 0.5500\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 1.2267 Acc: 0.5596\n",
      "val Loss: 1.2439 Acc: 0.5500\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 1.1891 Acc: 0.5687\n",
      "val Loss: 1.0956 Acc: 0.6071\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 1.1562 Acc: 0.5831\n",
      "val Loss: 1.0659 Acc: 0.6000\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 1.1150 Acc: 0.5979\n",
      "val Loss: 1.0486 Acc: 0.6071\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.0790 Acc: 0.6201\n",
      "val Loss: 1.0003 Acc: 0.6429\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 1.0615 Acc: 0.6215\n",
      "val Loss: 1.1255 Acc: 0.6071\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 1.0313 Acc: 0.6350\n",
      "val Loss: 1.0449 Acc: 0.6000\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 0.9954 Acc: 0.6454\n",
      "val Loss: 0.8788 Acc: 0.6500\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 0.9772 Acc: 0.6543\n",
      "val Loss: 1.0303 Acc: 0.6429\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 0.9628 Acc: 0.6586\n",
      "val Loss: 0.9070 Acc: 0.6643\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 0.9420 Acc: 0.6683\n",
      "val Loss: 0.9598 Acc: 0.6714\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 0.9275 Acc: 0.6713\n",
      "val Loss: 0.8802 Acc: 0.6643\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 0.9040 Acc: 0.6818\n",
      "val Loss: 0.8409 Acc: 0.6786\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 0.8970 Acc: 0.6861\n",
      "val Loss: 0.8221 Acc: 0.7000\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 0.8633 Acc: 0.6971\n",
      "val Loss: 0.8795 Acc: 0.6857\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 0.8614 Acc: 0.6940\n",
      "val Loss: 0.9219 Acc: 0.7000\n",
      "\n",
      "Training complete in 169m 27s\n",
      "Best val Acc: 0.700000\n",
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 1.8469 Acc: 0.2355\n",
      "val Loss: 1.6941 Acc: 0.3500\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.6905 Acc: 0.3252\n",
      "val Loss: 1.6672 Acc: 0.3214\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 1.6038 Acc: 0.3721\n",
      "val Loss: 1.5836 Acc: 0.4143\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 1.5117 Acc: 0.4294\n",
      "val Loss: 1.5497 Acc: 0.3786\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 1.4741 Acc: 0.4440\n",
      "val Loss: 1.4697 Acc: 0.4357\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 1.4610 Acc: 0.4533\n",
      "val Loss: 1.3862 Acc: 0.4857\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 1.4226 Acc: 0.4724\n",
      "val Loss: 1.4111 Acc: 0.4714\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 1.4010 Acc: 0.4846\n",
      "val Loss: 1.4439 Acc: 0.4857\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.3872 Acc: 0.4902\n",
      "val Loss: 1.4292 Acc: 0.5071\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 1.3769 Acc: 0.4962\n",
      "val Loss: 1.3036 Acc: 0.5214\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 1.3411 Acc: 0.5078\n",
      "val Loss: 1.3612 Acc: 0.5143\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 1.3320 Acc: 0.5117\n",
      "val Loss: 1.3693 Acc: 0.5071\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 1.3140 Acc: 0.5199\n",
      "val Loss: 1.3416 Acc: 0.5357\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 1.3094 Acc: 0.5244\n",
      "val Loss: 1.2228 Acc: 0.4929\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 1.3139 Acc: 0.5240\n",
      "val Loss: 1.2950 Acc: 0.5429\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 1.2918 Acc: 0.5357\n",
      "val Loss: 1.2662 Acc: 0.5571\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 1.2886 Acc: 0.5337\n",
      "val Loss: 1.2667 Acc: 0.5500\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 1.2840 Acc: 0.5407\n",
      "val Loss: 1.2299 Acc: 0.5500\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 1.2734 Acc: 0.5408\n",
      "val Loss: 1.1930 Acc: 0.5429\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 1.2826 Acc: 0.5416\n",
      "val Loss: 1.2691 Acc: 0.5071\n",
      "\n",
      "Training complete in 50m 28s\n",
      "Best val Acc: 0.557143\n",
      "Epoch 0/19\n",
      "----------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 122.50 MiB (GPU 0; 3.00 GiB total capacity; 1.75 GiB already allocated; 76.49 MiB free; 123.51 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-173d2a6c4921>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_history_scratch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloaders_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_inception\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"inception\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-391d22e8ca1a>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloaders, criterion, optimizer, num_epochs, is_inception)\u001b[0m\n\u001b[0;32m     43\u001b[0m                         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.4\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloss2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m                         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m                         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\torch\\lib\\site-packages\\torchvision\\models\\vgg.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   1621\u001b[0m     return torch.batch_norm(\n\u001b[0;32m   1622\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1623\u001b[1;33m         \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1624\u001b[0m     )\n\u001b[0;32m   1625\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 122.50 MiB (GPU 0; 3.00 GiB total capacity; 1.75 GiB already allocated; 76.49 MiB free; 123.51 MiB cached)"
     ]
    }
   ],
   "source": [
    "## basically, we loop through each model in the model_list\n",
    "\n",
    "model_list = ['resnet', 'alexnet', 'vgg', 'squeezenet', 'densenet']\n",
    "acc_history_scratch = {}\n",
    "for model_name in model_list:\n",
    "    # Initialize the non-pretrained version of the model used for this run\n",
    "    model,_ = initialize_model(model_name, num_classes, feature_extract=False, use_pretrained=False)\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    _, acc_history_scratch[model_name] = train_model(model, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "# of training epochs for the transfer learning method and\n",
    "# the model trained from scratch\n",
    "resnet = []\n",
    "alexnet = []\n",
    "vgg = []\n",
    "squeezenet = []\n",
    "densenet = []\n",
    "\n",
    "resnet = [h.cpu().numpy() for h in acc_history_scratch['resnet']]\n",
    "alexnet = [h.cpu().numpy() for h in acc_history_scratch['alexnet']]\n",
    "vgg = [h.cpu().numpy() for h in acc_history_scratch['vgg']]\n",
    "squeezenet = [h.cpu().numpy() for h in acc_history_scratch['squeezenet']]\n",
    "densenet = [h.cpu().numpy() for h in acc_history_scratch['densenet']]\n",
    "\n",
    "plt.title(\"Validation Accuracy vs. Epochs[Scratch]\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),resnet,label=\"Resnet\")\n",
    "plt.plot(range(1,num_epochs+1),alexnet,label=\"Alexnet\")\n",
    "plt.plot(range(1,num_epochs+1),vgg,label=\"VGG\")\n",
    "plt.plot(range(1,num_epochs+1),squeezenet,label=\"Squeezenet\")\n",
    "plt.plot(range(1,num_epochs+1),densenet,label=\"Densenet\")\n",
    "# plt.plot(range(1,num_epochs+1),inception,label=\"Inception\")\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
